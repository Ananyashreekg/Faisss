{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb0125a6-b963-4f5a-831b-bdea1d223a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\anany\\anaconda3\\lib\\site-packages (1.9.0.post1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\anany\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\anany\\anaconda3\\lib\\site-packages (from faiss-cpu) (23.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1767e554-df24-4f27-9611-e8ddc502d7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\n",
      "ERROR: No matching distribution found for faiss-gpu\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3096148f-5803-4006-bc1c-902a958fafbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f02d067f-fbc5-4d24-9309-aeb7a7a00109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in the index: 1000\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Initialize a Flat Index (brute-force search)\n",
    "dimension = 128  # Dimension of vectors\n",
    "index = faiss.IndexFlatL2(dimension)  # L2 distance (Euclidean)\n",
    "\n",
    "# Generate random vectors (e.g., embeddings)\n",
    "num_vectors = 1000\n",
    "vectors = np.random.random((num_vectors, dimension)).astype('float32')\n",
    "\n",
    "# Add vectors to the index\n",
    "index.add(vectors)\n",
    "\n",
    "print(f\"Number of vectors in the index: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45804471-d6af-4b23-9133-07f2ad16caa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: [[14.156978 14.640308 14.93914  15.006089 15.42473 ]]\n",
      "Indices of nearest neighbors: [[ 52 450 918 534 177]]\n"
     ]
    }
   ],
   "source": [
    "# Generate a query vector\n",
    "query_vector = np.random.random((1, dimension)).astype('float32')\n",
    "\n",
    "# Search for the 5 nearest neighbors\n",
    "k = 5\n",
    "distances, indices = index.search(query_vector, k)\n",
    "\n",
    "print(\"Distances:\", distances)\n",
    "print(\"Indices of nearest neighbors:\", indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b313ed9-ffcd-40d8-95e4-27834b9b7b88",
   "metadata": {},
   "source": [
    "Query Explanation\n",
    "Distances: Represents the similarity between the query vector and the retrieved vectors (lower is better for L2).\n",
    "Indices: Gives the positions of the retrieved vectors in the original dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d19bea-0ce6-483e-b44f-b84bc53408be",
   "metadata": {},
   "source": [
    "Key Concepts\n",
    "What is a Vector?\n",
    "\n",
    "A vector is a numerical representation of data, often generated by machine learning models.\n",
    "Example:\n",
    "Images: Extracted using CNN (ResNet, etc.).\n",
    "Text: Extracted using NLP models (BERT, word2vec).\n",
    "What is a Flat Index?\n",
    "\n",
    "A basic FAISS index that performs brute-force search to find the most similar vectors.\n",
    "Works well for smaller datasets (e.g., a few thousand vectors).\n",
    "What is L2 Distance?\n",
    "\n",
    "A measure of similarity where smaller distances indicate more similarity.\n",
    "Example:\n",
    "Two identical vectors have a distance of 0.\n",
    "Farther vectors have larger distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dbbdde4-abf5-478d-9d1d-1675a057030a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Vector: [[0.7279403  0.10713751 0.32860276 0.4993713  0.7423833  0.27279237\n",
      "  0.79273903 0.2916031  0.48047748 0.06298422 0.06591693 0.09477851\n",
      "  0.55380917 0.12910019 0.04598691 0.9078159  0.77033895 0.88538265\n",
      "  0.03636814 0.2612472  0.4319332  0.62366617 0.505568   0.096889\n",
      "  0.5075388  0.11634566 0.8683764  0.9852671  0.97208357 0.09180584\n",
      "  0.32982185 0.21606591 0.9732137  0.27511105 0.99516237 0.11287562\n",
      "  0.15530793 0.8789886  0.9932234  0.49323556 0.24727508 0.533561\n",
      "  0.7541848  0.04145546 0.27339694 0.8266389  0.06087651 0.29161167\n",
      "  0.7918901  0.70615387 0.24259007 0.7554129  0.13981779 0.6970747\n",
      "  0.58426106 0.8528335  0.79104716 0.2480611  0.4978429  0.95577997\n",
      "  0.60850316 0.19041154 0.18559423 0.95386124 0.30269492 0.23273489\n",
      "  0.6286228  0.90319395 0.46590626 0.61094815 0.316676   0.9066248\n",
      "  0.792105   0.81925005 0.83912486 0.27209285 0.02078237 0.80653065\n",
      "  0.5683758  0.6223491  0.19222236 0.5523597  0.88503015 0.8711004\n",
      "  0.46168157 0.5705977  0.71410024 0.189267   0.16963422 0.22020878\n",
      "  0.95701617 0.5903348  0.8722426  0.9367947  0.4079485  0.6628709\n",
      "  0.9817354  0.94494724 0.8503241  0.72630787 0.45925564 0.43280727\n",
      "  0.09735448 0.6417511  0.18223014 0.71657765 0.46068278 0.65362495\n",
      "  0.8181437  0.4893499  0.71300066 0.14252134 0.8312419  0.2452811\n",
      "  0.49329177 0.21872088 0.78664356 0.4617454  0.7675514  0.85583675\n",
      "  0.9328931  0.47696334 0.9089815  0.6835787  0.24404833 0.7520358\n",
      "  0.7212027  0.891258  ]]\n",
      "Distances to Neighbors: [[14.842969  15.0691185 16.131634  16.1535    16.343662 ]]\n",
      "Indices of Neighbors: [[315 950 827 973 938]]\n"
     ]
    }
   ],
   "source": [
    "# Generate a random query vector (e.g., similar to embeddings from a new image)\n",
    "query_vector = np.random.random((1, dimension)).astype('float32')\n",
    "\n",
    "# Perform a search for the 5 nearest neighbors\n",
    "k = 5  # Number of nearest neighbors to retrieve\n",
    "distances, indices = index.search(query_vector, k)\n",
    "\n",
    "# Print the results\n",
    "print(\"Query Vector:\", query_vector)\n",
    "print(\"Distances to Neighbors:\", distances)\n",
    "print(\"Indices of Neighbors:\", indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb4f8fb0-7826-4ad9-a769-fa88e74d8fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\anany\\anaconda3\\lib\\site-packages (1.9.0.post1)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\anany\\anaconda3\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\anany\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\anany\\anaconda3\\lib\\site-packages (from faiss-cpu) (23.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\anany\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.46.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anany\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\anany\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\anany\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\anany\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\anany\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.26.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\anany\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\anany\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\anany\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\anany\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\anany\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\anany\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\anany\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anany\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\anany\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\anany\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\anany\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\anany\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\anany\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\anany\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\anany\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\anany\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anany\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anany\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anany\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anany\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anany\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu sentence-transformers numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "766f760c-dd3f-4ba8-8259-845e3b42021a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\anany\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Number of sentence embeddings in the index: 5\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Initialize the Sentence Transformer model to get sentence embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Example sentences\n",
    "sentences = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"I love programming in Python.\",\n",
    "    \"Artificial intelligence is transforming the world.\",\n",
    "    \"Machine learning is a subset of artificial intelligence.\",\n",
    "    \"Deep learning models are highly effective for image recognition.\"\n",
    "]\n",
    "\n",
    "# Generate sentence embeddings (each sentence is converted to a 384-dimensional vector)\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Convert embeddings to numpy array (float32 type is required by FAISS)\n",
    "embeddings = np.array(embeddings).astype('float32')\n",
    "\n",
    "# Initialize FAISS index for L2 distance\n",
    "dimension = embeddings.shape[1]  # 384 dimensions for the 'all-MiniLM-L6-v2' model\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Add embeddings to the FAISS index\n",
    "index.add(embeddings)\n",
    "\n",
    "# Check the number of vectors in the index\n",
    "print(f\"Number of sentence embeddings in the index: {index.ntotal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf27c053-4106-4ad3-a1db-21b287925d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04393355  0.05893443  0.04817838 ...  0.05216278  0.05610652\n",
      "   0.10206394]\n",
      " [-0.05761699  0.00426226 -0.02815318 ...  0.11543837  0.10225611\n",
      "  -0.01581942]\n",
      " [ 0.03872415 -0.00110552  0.08271618 ... -0.02902935  0.04854367\n",
      "  -0.03839865]\n",
      " [-0.02345928 -0.01058114  0.07192817 ...  0.06038335  0.07951811\n",
      "  -0.04710237]\n",
      " [-0.01509204 -0.06898728  0.07579856 ...  0.02140344 -0.05689414\n",
      "  -0.04317182]]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d52ac5d5-ffbe-43ab-a240-303abd7f5e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<faiss.swigfaiss_avx2.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x000001BC64328120> >\n"
     ]
    }
   ],
   "source": [
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e200c1d1-1cbe-4e37-866a-4b98e9960806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Sentence: I enjoy coding in Python.\n",
      "\n",
      "Most similar sentences:\n",
      "Sentence: I love programming in Python. - Distance: 0.12243586778640747\n",
      "Sentence: Artificial intelligence is transforming the world. - Distance: 1.4568238258361816\n"
     ]
    }
   ],
   "source": [
    "# Query sentence\n",
    "query_sentence = \"I enjoy coding in Python.\"\n",
    "\n",
    "# Convert the query sentence to an embedding\n",
    "query_embedding = model.encode([query_sentence])\n",
    "\n",
    "# Perform the search for the 2 most similar sentences\n",
    "k = 2  # Number of nearest neighbors to retrieve\n",
    "distances, indices = index.search(np.array(query_embedding).astype('float32'), k)\n",
    "\n",
    "# Print the query and the most similar sentences\n",
    "print(f\"Query Sentence: {query_sentence}\")\n",
    "print(\"\\nMost similar sentences:\")\n",
    "for i in range(k):\n",
    "    print(f\"Sentence: {sentences[indices[0][i]]} - Distance: {distances[0][i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87f0cba-7d03-4396-9efc-af00cafe346e",
   "metadata": {},
   "source": [
    " Sentence Embedding Generation:\n",
    "First, the sentences are passed through the SentenceTransformer model ('all-MiniLM-L6-v2'), which generates 384-dimensional embeddings for each sentence. This means that each sentence is represented by a 384-dimensional vector (array of floating-point numbers). These embeddings capture the semantic meaning of the sentences.\n",
    "\"The quick brown fox jumps over the lazy dog.\"\r",
    "[0.12, -0.34, 0.56, ..., 0.98, -0.12]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77e8afa-738b-43ed-b416-68dfae892fe3",
   "metadata": {},
   "source": [
    "FAISS Indexing:\n",
    "Next, these embeddings are added to a FAISS index using index.add(embeddings). FAISS is designed to efficiently store and search vectors in high-dimensional space. Here's what happens:\n",
    "\n",
    "FAISS Index: The IndexFlatL2 is used here, which is a simple, brute-force search index. The L2 in IndexFlatL2 refers to the Euclidean distance used for comparison. This means that when you query the index, FAISS will measure the Euclidean distance between the query vector and all vectors in the index to find the closest matches.\n",
    "\n",
    "Storing Embeddings: The embeddings are stored directly in the FAISS index. FAISS uses an internal structure to organize the vectors, allowing it to search them efficiently later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3371491-0ca7-4c93-94f4-5ff6970a931b",
   "metadata": {},
   "source": [
    "Storing the Embeddings:\n",
    "Indexing Process: When you add embeddings to the FAISS index using index.add(embeddings), the embeddings are stored in memory or a persistent file (depending on how FAISS is configured). The internal representation might look like a high-dimensional matrix, where each row corresponds to a sentence embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef42128a-e638-417a-80a3-a27b12a3a6a9",
   "metadata": {},
   "source": [
    "\n",
    "        Sentence\t                                                 Embedding (384-dimensional vector)\n",
    "\"The quick brown fox jumps over the lazy dog.\"\t                    [0.12, -0.34, 0.56, ..., 0.98, -0.12]\n",
    "\"I love programming in Python.\"\t                                    [0.23, -0.12, 0.45, ..., 0.76, -0.54]\n",
    "\"Artificial intelligence is transforming the world.\"                [0.56, 0.34, 0.67, ..., 0.34, -0.76]\n",
    "\"Machine learning is a subset of artificial intelligence.\"\t        [0.21, -0.67, 0.45, ..., 0.78, 0.12]\n",
    "\"Deep learning models are highly effective for image recognition.\"\t[0.43, -0.22, 0.34, ..., 0.56, 0.45]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef6b195-bd19-4e63-98c9-b4c066aa3e3a",
   "metadata": {},
   "source": [
    "Flat Index (IndexFlatL2):\n",
    "\n",
    "This is a simple, brute-force index where all vectors are stored directly in memory.\n",
    "The number of vectors it can store depends on the available system memory (RAM). It will scale linearly with the number of vectors, so as the dataset grows, the memory required to store these vectors grows.\n",
    "For example, if you have 100,000 vectors and each vector has a dimension of 128, the memory required will be 100,000 * 128 * 4 bytes (since each float32 element is 4 bytes).\n",
    "Inverted File Index (IVF):\n",
    "\n",
    "The Inverted File Index (IVF) is designed to be more memory-efficient for large datasets.\n",
    "Instead of storing all vectors in memory, it partitions the data into groups (clusters) and uses an inverted index to store and retrieve the vectors.\n",
    "IVF can scale to millions of vectors by using disk storage in addition to memory, so it can handle much larger datasets compared to a FlatL2 index.\n",
    "HNSW (Hierarchical Navigable Small World) Index:\n",
    "\n",
    "The HNSW index is a graph-based index that is highly efficient for large-scale vector searches.\n",
    "It organizes vectors in a hierarchical graph structure and is very memory efficient compared to FlatL2.\n",
    "HNSW can handle millions of vectors while maintaining fast search times, but the memory usage depends on the number of neighbors stored per vector (which can be adjusted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2227bb01-45cc-4974-b7a2-a86397588d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
